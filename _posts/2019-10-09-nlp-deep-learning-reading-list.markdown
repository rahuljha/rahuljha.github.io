Here is a list of resources for various topics related to deep learning in NLP. I've organized them so you can read them in the order given.

*  General background
   * [Noah's paper](https://arxiv.org/pdf/1902.06006.pdf) on history of word representations 
   * [Yoav's primer](https://arxiv.org/abs/1510.00726) on DL in NLP, circa 2015
*  LSTM: [Colah's classic blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
*  CNN: [WildML article](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)
*  Attention: 
   * [Wildml article](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/) for high level understanding
   * [Heuritech article](https://lab.heuritech.com/attention-mechanism) for more details
* Transformers:
   * [Jay Alamar's blog](http://jalammar.github.io/illustrated-transformer/) for big picture
   * [Peter Bloem's blog](http://www.peterbloem.nl/blog/transformers) for more detailed intro
* BERT: [Jay Alamar's blog]( http://jalammar.github.io/illustrated-bert/)
* Retrieval Transformer: 
   * [Jay Alamar's blog](https://jalammar.github.io/illustrated-retrieval-transformer/)
   * [DeepMind blog](https://deepmind.com/blog/article/language-modelling-at-scale)
 * Optimizing DNN's
   * [EMNLP 2020 tutorial](http://gabrielilharco.com/publications/EMNLP_2020_Tutorial__High_Performance_NLP.pdf)

